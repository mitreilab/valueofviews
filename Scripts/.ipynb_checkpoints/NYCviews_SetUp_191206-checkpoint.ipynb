{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import glob\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "from subprocess import Popen\n",
    "from multiprocessing import Pool\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating points on a sphere "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "theta_max = 40      # angle above horizontal (0-90 deg)\n",
    "theta_min = 70      # angle below horizontal (0-90 deg, can be positive or negative)\n",
    "n = 10000             # n = number of points on the sphere (full sphere, before cutting off range of vision)\n",
    " \n",
    "golden_angle = np.pi * (3 - np.sqrt(5))\n",
    "theta = golden_angle * np.arange(n)      # create an array with n elements\n",
    "z = np.linspace(1 - 1.0 / n, 1.0 / n - 1, n)     # array with linear spacing from 1-1/n to 1/n-1 with n elements \n",
    "radius = np.sqrt(1 - z * z)\n",
    " \n",
    "#selectTheta = np.array[(theta > theta.min) & (theta < theta.max)]\n",
    "\n",
    "# Create points = array of n elements with [0, 0, 0]\n",
    "points = np.zeros((n, 3))\n",
    "\n",
    "points[:,0] = radius * np.cos(theta)\n",
    "points[:,1] = radius * np.sin(theta)\n",
    "points[:,2] = z\n",
    "\n",
    "#select only points within range of vision\n",
    "angle_max = abs(theta_max)/90\n",
    "angle_min = -abs(theta_min)/90\n",
    "selectPts = np.delete(points, np.where(np.logical_or(points[:,2]>angle_max, points[:,2]<=angle_min)), axis=0)\n",
    "\n",
    "print(selectPts.shape)\n",
    "\n",
    "# Convert the rays array to dataframe\n",
    "all_rays_df = pd.DataFrame(selectPts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot test\n",
    "pts_x = selectPts[:,0]\n",
    "pts_y = selectPts[:,1]\n",
    "pts_z = selectPts[:,2]\n",
    " \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter3D(pts_x, pts_y, pts_z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for prepping BIN Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FUNCTION: Concatenate all the pts for all floors into one dataframe\n",
    "def concatenateAllPts(sourceDir, BIN):\n",
    "   \n",
    "    #sourceDir: the directory for all BIN folders\n",
    "    #BIN: name of BIN (string)\n",
    "\n",
    "    #Make list of all .pts file in directory\n",
    "    os.chdir(sourceDir + \"\\\\\" + BIN)\n",
    "    all_lines = []\n",
    "    for file in glob.glob(\"*.pts\"): \n",
    "\n",
    "        # Read .pts file into list and convert to DF\n",
    "        with open(sourceDir + \"\\\\\" + BIN + \"\\\\\" + file) as f: \n",
    "            lines = f.readlines()\n",
    "        lines = [x.strip() for x in lines]\n",
    "        for i in range(len(lines)): \n",
    "            oneRow = list(map(float, lines[i].split()))\n",
    "            del oneRow[-3:]\n",
    "            all_lines.append(oneRow)\n",
    "\n",
    "    #Create dataframe with points for all floors in BIN\n",
    "    BIN_pts_df = pd.DataFrame(all_lines)\n",
    "    BIN_pts_df.columns = [\"x\", \"y\", \"z\"]\n",
    "\n",
    "    #print(BIN_pts_df.head())\n",
    "    print(\"---> # of points in all floors in BIN (# rows):\", BIN_pts_df.shape)\n",
    "    #print(BIN_pts_df.shape)\n",
    "\n",
    "    #Check that all floors are represented\n",
    "    #print(\"z value of all floors:\")\n",
    "    #print(BIN_pts_df[\"z\"].unique())\n",
    "    \n",
    "    return(BIN_pts_df)\n",
    "\n",
    "# FUNCTION: Create the rays for each point in the BIN grids\n",
    "def createGridRays(ray_vec_df, BIN_pts_df):\n",
    "\n",
    "    # ray_vec_df: the trace to trace in a dataframe \n",
    "    # BIN_pts_df: all points in the BIN in a dataframe\n",
    "    \n",
    "    # Duplicate each row of grid point df by size of vector df and add ray index column\n",
    "    vectors_df = pd.DataFrame(np.repeat(BIN_pts_df.values, len(ray_vec_df.index), axis=0))\n",
    "    vectors_df['ray_count'] = vectors_df.groupby(0).cumcount()\n",
    "    vectors_df = vectors_df.reset_index(drop=True)\n",
    "\n",
    "    all_vectors = pd.merge(vectors_df, ray_vec_df, left_on='ray_count', right_index=True)\n",
    "    all_vectors = all_vectors.drop(['ray_count'], axis=1)\n",
    "    grid_vectors = all_vectors.sort_index()\n",
    "\n",
    "    print(\"---> shape of grid df (# points x # rays):\", grid_vectors.shape)\n",
    "    #print(grid_vectors.shape)\n",
    "    \n",
    "    return(grid_vectors)\n",
    "\n",
    "# FUNCTION: Export dataframe to CSV (TAKES A LONG TIME -- V BIG FILES!)\n",
    "def writeGridRaystoCSV(grid_vectors, sourceDir, BIN):\n",
    "\n",
    "    #grid_vectors: the output from createGridRays\n",
    "    #sourceDir: the directory for all BIN folders\n",
    "    #BIN: name of BIN (string)\n",
    "    \n",
    "    print(\"---> WRITE_START:\", datetime.now())\n",
    "    csvFile = sourceDir + \"\\\\\" + BIN + \"\\\\\" + BIN + \"_rays.csv\"\n",
    "    grid_vectors.to_csv(csvFile, sep=\" \", header=False, index=False)\n",
    "    print(\"---> WRITE_END:\", datetime.now())\n",
    "\n",
    "    # Check the file size\n",
    "    size = os.path.getsize(csvFile)\n",
    "    print(\"---> csv file size: \" + str(size/1e+6) + \"mb\")\n",
    "\n",
    "# FUNCTION: Plot test the grid vectors \n",
    "def plotGridVectorsTest(grid_vectors):\n",
    "    \n",
    "    #Take a small portion of the vectors \n",
    "    grid_slice = grid_vectors.truncate(after=600)\n",
    "\n",
    "    fig=plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.quiver(grid_slice[\"0_x\"], grid_slice[\"1_x\"], grid_slice[\"2_x\"], grid_slice[\"0_y\"], grid_slice[\"1_y\"], grid_slice[\"2_y\"])\n",
    "\n",
    "    #ax.set_zlim(-1.01, 1.01)\n",
    "\n",
    "    ax.view_init(azim=0, elev=90)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create csv with ray for full floor analysis grid --- all floors in BIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#NYCsourceDir = r\"C:\\Users\\ituran\\NYCstudy\\BINS\"\n",
    "NYCsourceDir = r\"D:\\ituran\\NYCviews\\BINS_to_do\"\n",
    "\n",
    "# Loop through all BINS in directory \n",
    "for file in os.listdir(NYCsourceDir): \n",
    "    print(\"---\")\n",
    "    print(file+\"_START\", datetime.now())\n",
    "    \n",
    "    print(file + \"_1 concatenate all points in BIN\")\n",
    "    # made dataframe with the points on all floors in the BIN\n",
    "    allflr_pt_df = concatenateAllPts(NYCsourceDir, file)\n",
    "\n",
    "    print(file + \"_2 make vector for all points in BIN\")\n",
    "    # apply vector rays to all points on all floors in the BIN\n",
    "    allflr_vector_df = createGridRays(all_rays_df, allflr_pt_df)\n",
    "    \n",
    "    print(file + \"_3 write vector df to CSV\")\n",
    "    # write the vector array to a file\n",
    "    writeGridRaystoCSV(allflr_vector_df, NYCsourceDir, file)\n",
    "\n",
    "    print(file+\"_END\", datetime.now())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create batch file in each BIN folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BINSourceDir = r'D:\\ituran\\NYCviews\\BINS'\n",
    "source_batch = r\"D:\\ituran\\NYCviews\\SimFiles\\views_batch_master_D.bat\"\n",
    "\n",
    "# New input text\n",
    "input_scene_cd = r'D:\\ituran\\NYCviews\\RadScene'\n",
    "input_oct = r'D:\\ituran\\NYCviews\\RadScene\\NYCmodel_all_wSkyandViews_200124.oct'\n",
    "\n",
    "for file in os.listdir(BINSourceDir): \n",
    "    \n",
    "    # Read the source batch file template\n",
    "    with open(source_batch, \"r\") as f: \n",
    "        sourceFile = f.readlines()\n",
    "\n",
    "    for i in range(len(sourceFile)): \n",
    "        sourceFile[i] = sourceFile[i].replace('cd', 'cd ' + input_scene_cd)\n",
    "        sourceFile[i] = sourceFile[i].replace('set octreefile=', 'set octreefile=' + input_oct)\n",
    "        sourceFile[i] = sourceFile[i].replace('set rayFile=', 'set rayFile=' + BINSourceDir + '\\\\' + file + '\\\\' + file + '_rays.csv')\n",
    "        sourceFile[i] = sourceFile[i].replace('set resultsFile=', 'set resultsFile=' + BINSourceDir + '\\\\' + file + '\\\\' + file + '_out.dat')\n",
    "\n",
    "    newBat = BINSourceDir + '\\\\' + file + '\\\\' 'view_batch_d.bat'\n",
    "    with open(newBat, 'w') as out: \n",
    "        for i in sourceFile: \n",
    "            out.write(i)\n",
    "\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create loop for the batch simulations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filename of the batch file\n",
    "filepath = r\"D:\\ituran\\NYCviews\\BINS\"\n",
    "outputpath = r\"D:\\ituran\\NYCviews\\Log\"\n",
    "logName = 'NYCviews_logfile.txt'\n",
    "batchFile = \"view_batch_d.bat\" \n",
    "\n",
    "\n",
    "########################################################################\n",
    "######## FUNCTIONS ########\n",
    "########################################################################\n",
    "\n",
    "# Get a list of the immediate subdirectories in a folder\n",
    "def get_immediate_subdirs(a_dir):\n",
    "    return [name for name in os.listdir(a_dir)\n",
    "            if os.path.isdir(os.path.join(a_dir, name))]\n",
    "\n",
    "\n",
    "# takes a directory with a batch file\n",
    "# runs the batch file in a subprocess\n",
    "def runSim(dirName):\n",
    "    with open(outputpath +'\\\\' + logName, 'a+') as f:\n",
    "        f.write(\"Start: \"+ dirName+' at {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())+'\\n')\n",
    "        \n",
    "    #child = Popen(batchFile, cwd = filepath + \"\\\\\" + dirName)\n",
    "    child = Popen(filepath + \"\\\\\" + dirName + '\\\\' + batchFile)\n",
    "    child.wait()\n",
    "    \n",
    "    with open(outputpath +'\\\\' + logName, 'a+') as f:\n",
    "        f.write('Stop: '+dirName+' at {:%Y-%m-%d %H:%M:%S}'.format(datetime.datetime.now())+'\\n')\n",
    "        f.write('Return code: '+str(child.returncode)+'\\n')\n",
    "    \n",
    " \n",
    "\n",
    "########################################################################\n",
    "######## CODE ########\n",
    "########################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "# create a list of directories, each containing a batch file\n",
    "# corresponding to a radiance simulation\n",
    "    all_Floors = get_immediate_subdirs(filepath)\n",
    "    print(all_Floors)\n",
    "    \n",
    "    #p = Pool()\n",
    "    #p.map(runSim, all_Floors)\n",
    "    \n",
    "\n",
    "# all_Floors is a list of simulation folders containing bat files\n",
    "# now we can create a pool of workers to run runSim on each \n",
    "\n",
    "# create a pool of workers to run each batch file\n",
    "# The processes arg is None, so we use the number of cores in the computer\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE BELOW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through all .pts files in the directory (glob does not keep order!)\n",
    "BINdir = r\"C:\\Users\\ituran\\NYCstudy\\testFolder\" \n",
    "BIN = str(1000007)\n",
    "\n",
    "print(str(BINdir + \"\\\\\" + BIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make list of all .pts file in directory\n",
    "os.chdir(BINdir + \"\\\\\" + BIN)\n",
    "all_lines = []\n",
    "for file in glob.glob(\"*.pts\"): \n",
    "    \n",
    "    # Read .pts file into list and convert to DF\n",
    "    with open(BINdir + \"\\\\\" + BIN + \"\\\\\" + file) as f: \n",
    "        lines = f.readlines()\n",
    "    lines = [x.strip() for x in lines]\n",
    "    for i in range(len(lines)): \n",
    "        oneRow = list(map(float, lines[i].split()))\n",
    "        del oneRow[-3:]\n",
    "        all_lines.append(oneRow)\n",
    "\n",
    "#Create dataframe with points for all floors in BIN\n",
    "BIN_pts_df = pd.DataFrame(all_lines)\n",
    "BIN_pts_df.columns = [\"x\", \"y\", \"z\"]\n",
    "\n",
    "#print(BIN_pts_df.head())\n",
    "print(BIN_pts_df.shape)\n",
    "\n",
    "#Check that all floors are represented\n",
    "print(BIN_pts_df[\"z\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the rays array to dataframe\n",
    "ray_vec_df = pd.DataFrame(selectPts)\n",
    "\n",
    "# Duplicate each row of grid point df by size of vector df and add ray index column\n",
    "vectors_df = pd.DataFrame(np.repeat(BIN_pts_df.values, len(ray_vec_df.index), axis=0))\n",
    "vectors_df['ray_count'] = vectors_df.groupby(0).cumcount()\n",
    "vectors_df = vectors_df.reset_index(drop=True)\n",
    "\n",
    "all_vectors = pd.merge(vectors_df, ray_vec_df, left_on='ray_count', right_index=True)\n",
    "all_vectors = all_vectors.drop(['ray_count'], axis=1)\n",
    "grid_vectors = all_vectors.sort_index()\n",
    "\n",
    "# #BLOCK COMMENT SHORTCUT: cmd + / \n",
    "# #print(BIN_pts_df)\n",
    "# print(len(grid_vectors.index))\n",
    "# print(len(ray_vec_df.index))\n",
    "# print(len(vectors_df.index))\n",
    "# print(grid_vectors[0:10])\n",
    "# print(grid_vectors[300:310])\n",
    "# print(ray_vec_df[0:10])\n",
    "\n",
    "print(grid_vectors.shape)\n",
    "print(grid_vectors['0_x'].idxmax())\n",
    "print(grid_vectors['0_x'].idxmin())\n",
    "print(grid_vectors['1_x'].idxmax())\n",
    "print(grid_vectors['1_x'].idxmin())\n",
    "print(grid_vectors[609:615])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot test the grid vectors \n",
    "\n",
    "#Take a small portion of the vectors \n",
    "grid_slice = grid_vectors.truncate(after=600)\n",
    "\n",
    "fig=plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.quiver(grid_slice[\"0_x\"], grid_slice[\"1_x\"], grid_slice[\"2_x\"], grid_slice[\"0_y\"], grid_slice[\"1_y\"], grid_slice[\"2_y\"])\n",
    "\n",
    "#ax.set_zlim(-1.01, 1.01)\n",
    "\n",
    "ax.view_init(azim=0, elev=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Export dataframe to CSV\n",
    "grid_vectors.to_csv(BINdir + \"\\\\\" + BIN + \"\\\\\" + BIN + \"_rays.csv\", \\\n",
    "                    sep=\" \", header=False, index=False)\n",
    "\n",
    "#### TAKES A WHILE TO SAVE! ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test that CSV saved properly \n",
    "csvFile = BINdir + \"\\\\\" + BIN + \"\\\\\" + BIN + \"_rays.csv\"\n",
    "\n",
    "with open(csvFile, 'r') as f: \n",
    "    reader = csv.reader(f, delimiter = \" \")\n",
    "    data = list(reader)\n",
    "    data = np.array(data).astype(float)\n",
    "\n",
    "print(data.shape)\n",
    "print(data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write batch file for floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- OLD CODE --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up batch file and copy other input files to directory \n",
    "\n",
    "partsPath = dirPath + ' - parts'\n",
    "masterBatch = simDir + '\\\\' + 'views_batch_master.bat'\n",
    "masterBatRev = dirPath + '\\\\' + 'views_batch.bat'\n",
    "\n",
    "# Copy input files into diretory \n",
    "otherFiles = ['sky.rad', 'geom.rad', 'geom.oct']\n",
    "for i in otherFiles: \n",
    "    shutil.copyfile(partsPath + '\\\\' + i, dirPath + '\\\\' + i)\n",
    "\n",
    "# Create the batch file\n",
    "with open(masterBatch, 'r') as f: \n",
    "    masterBatFile = f.readlines()\n",
    "    \n",
    "for i in range(len(masterBatFile)): \n",
    "    masterBatFile[i] = masterBatFile[i].replace('cd', 'cd ' + dirPath)\n",
    "    masterBatFile[i] = masterBatFile[i].replace('set skyfile=', 'set skyfile=' + dirPath + '\\\\' + 'sky.rad')\n",
    "    masterBatFile[i] = masterBatFile[i].replace('set geofile=', 'set geofile=' + dirPath + '\\\\' + 'geom.rad')\n",
    "    masterBatFile[i] = masterBatFile[i].replace('set octreefile=', 'set octreefile=' + dirPath + '\\\\' + 'geom.oct')\n",
    "    masterBatFile[i] = masterBatFile[i].replace('set rayFile=', 'set rayFile=' + dirPath + '\\\\' + name + '.txt')\n",
    "    masterBatFile[i] = masterBatFile[i].replace('set resultsFile=', 'set resultsFile=' + dirPath + '\\\\' + name + '.dat')\n",
    "\n",
    "with open(masterBatRev, 'w') as out: \n",
    "    for i in masterBatFile: \n",
    "        out.write(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run batch file "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Run batch file with oconv and rtrace\n",
    "if run == True: \n",
    "    p = subprocess.Popen(masterBatRev)\n",
    "    p.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [NAS_ituran]",
   "language": "python",
   "name": "Python [NAS_ituran]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
